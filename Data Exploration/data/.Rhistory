df <- merge(comments_french, ndf, by = "url", all.x = TRUE)
######## Partie 1:  Marrakech
df_marr <- df[df$location == "Marrakch", ]
df_marr <- na.omit(df_marr)
library(mongolite)
library(ggplot2)
library(cowplot)
library(reshape2)
library(stats)
library(dplyr)
library(stringr)
connection_string = 'mongodb://localhost:27017'
#################### Attractions
attractions = mongo(collection="attractions", db="tripadvisor", url=connection_string)
comments = mongo(collection="comments", db="tripadvisor", url=connection_string)
attractions$count()
df <- as.data.frame(attractions$find())
ndf <- distinct(df, title, .keep_all = TRUE)
location = c()
for(i in 1:nrow(ndf)){
if(str_detect(ndf$url[i],'g60763')){
location <- c(location,'New-york')
} else if(str_detect(ndf$url[i],'g295424')){
location <- c(location,'Dubai')
} else if(str_detect(ndf$url[i],'g293734')){
location <- c(location,'Marrakch')
} else if(str_detect(ndf$url[i],'g189158')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189146')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g315902')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189112')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g642199')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189171')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Portugal')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Faro_District_Algarve')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Ile_de_France')){
location <- c(location,'France')
} else{
location <- c(location,NA)
}
}
ndf$location <- location
rm(i, location)
type = c()
for(i in 1:nrow(ndf)){
if(!is.na(ndf$tags[[i]][2])){
if(str_detect(ndf$tags[[i]][2],'Spas et bien-être')){
type <- c(type, 'Spas et bien-être')
} else if(str_detect(ndf$tags[[i]][2],'plein') && str_detect(ndf$tags[[i]][2],'air')){
type <- c(type, 'Activités de plein air')
} else if(str_detect(ndf$tags[[i]][2],'Circuits et activités')){
type <- c(type, 'Circuits et activités')
} else if(str_detect(ndf$tags[[i]][2],'Vie') && str_detect(ndf$tags[[i]][2],'nocturne')){
type <- c(type, 'Vie nocturne')
} else if(str_detect(ndf$tags[[i]][2],'activités')){
type <- c(type, 'Activités')
} else if(str_detect(ndf$tags[[i]][2],'Boire & manger')){
type <- c(type, 'Boire & manger')
} else if(str_detect(ndf$tags[[i]][2],'Shopping')){
type <- c(type, 'Shopping')
} else if(str_detect(ndf$tags[[i]][2],'Transports')){
type <- c(type, 'Transports')
} else if(str_detect(ndf$tags[[i]][2],'Cours et atelier')){
type <- c(type, 'Cours et atelier')
} else if(str_detect(ndf$tags[[i]][2],'Sites touristiques')){
type <- c(type, 'Sites touristiques')
} else {
type <- c(type, 'Autres')
}
} else {
type <- c(type, NA)
}
}
ndf$type <- type
rm(i, type)
rm(df)
#################### Comments
regex_pattern <- "France"
query <- paste0(paste0('{"comment_location": {"$regex": "',regex_pattern),'", "$options": "i"}}')
comments_french <- as.data.frame(comments$find(query = query))
#################### Final DF
df <- merge(comments_french, ndf, by = "url", all.x = TRUE)
######## Partie 1:  Marrakech
df_marr <- df[df$location == "Marrakch", ]
df_marr <- na.omit(df_marr)
result <- df_marr %>%
group_by(profile_name, title)
View(result)
result <- df_marr %>%
group_by(profile_name, title)  %>%
summarize(
number_visits = sum(attraction)
)
df_marr$attraction <- rep(1, nrow(df_marr))
result <- df_marr %>%
group_by(profile_name, title)  %>%
summarize(
number_visits = sum(attraction)
)
View(result)
# Appliquer la fonction dcast pour revenir au format large
data_wide <- dcast(result, profile_name ~ title, value.var = "number_visits")
View(data_wide)
install.packages("arules")
install.packages("arules")
library(arules)
install.packages("Matrix")
library(arules)
transactions_arules <- as(data_wide, "transactions")
library(mongolite)
library(ggplot2)
library(cowplot)
library(reshape2)
library(stats)
library(dplyr)
library(stringr)
connection_string = 'mongodb://localhost:27017'
#################### Attractions
attractions = mongo(collection="attractions", db="tripadvisor", url=connection_string)
comments = mongo(collection="comments", db="tripadvisor", url=connection_string)
attractions$count()
df <- as.data.frame(attractions$find())
ndf <- distinct(df, title, .keep_all = TRUE)
location = c()
for(i in 1:nrow(ndf)){
if(str_detect(ndf$url[i],'g60763')){
location <- c(location,'New-york')
} else if(str_detect(ndf$url[i],'g295424')){
location <- c(location,'Dubai')
} else if(str_detect(ndf$url[i],'g293734')){
location <- c(location,'Marrakch')
} else if(str_detect(ndf$url[i],'g189158')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189146')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g315902')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189112')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g642199')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189171')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Portugal')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Faro_District_Algarve')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Ile_de_France')){
location <- c(location,'France')
} else{
location <- c(location,NA)
}
}
ndf$location <- location
rm(i, location)
type = c()
for(i in 1:nrow(ndf)){
if(!is.na(ndf$tags[[i]][2])){
if(str_detect(ndf$tags[[i]][2],'Spas et bien-être')){
type <- c(type, 'Spas et bien-être')
} else if(str_detect(ndf$tags[[i]][2],'plein') && str_detect(ndf$tags[[i]][2],'air')){
type <- c(type, 'Activités de plein air')
} else if(str_detect(ndf$tags[[i]][2],'Circuits et activités')){
type <- c(type, 'Circuits et activités')
} else if(str_detect(ndf$tags[[i]][2],'Vie') && str_detect(ndf$tags[[i]][2],'nocturne')){
type <- c(type, 'Vie nocturne')
} else if(str_detect(ndf$tags[[i]][2],'activités')){
type <- c(type, 'Activités')
} else if(str_detect(ndf$tags[[i]][2],'Boire & manger')){
type <- c(type, 'Boire & manger')
} else if(str_detect(ndf$tags[[i]][2],'Shopping')){
type <- c(type, 'Shopping')
} else if(str_detect(ndf$tags[[i]][2],'Transports')){
type <- c(type, 'Transports')
} else if(str_detect(ndf$tags[[i]][2],'Cours et atelier')){
type <- c(type, 'Cours et atelier')
} else if(str_detect(ndf$tags[[i]][2],'Sites touristiques')){
type <- c(type, 'Sites touristiques')
} else {
type <- c(type, 'Autres')
}
} else {
type <- c(type, NA)
}
}
ndf$type <- type
rm(i, type)
rm(df)
#################### Comments
regex_pattern <- "France"
query <- paste0(paste0('{"comment_location": {"$regex": "',regex_pattern),'", "$options": "i"}}')
comments_french <- as.data.frame(comments$find(query = query))
library(mongolite)
library(ggplot2)
library(cowplot)
library(reshape2)
library(stats)
library(dplyr)
library(stringr)
connection_string = 'mongodb://localhost:27017'
#################### Attractions
attractions = mongo(collection="attractions", db="tripadvisor", url=connection_string)
comments = mongo(collection="comments", db="tripadvisor", url=connection_string)
attractions$count()
df <- as.data.frame(attractions$find())
ndf <- distinct(df, title, .keep_all = TRUE)
location = c()
for(i in 1:nrow(ndf)){
if(str_detect(ndf$url[i],'g60763')){
location <- c(location,'New-york')
} else if(str_detect(ndf$url[i],'g295424')){
location <- c(location,'Dubai')
} else if(str_detect(ndf$url[i],'g293734')){
location <- c(location,'Marrakch')
} else if(str_detect(ndf$url[i],'g189158')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189146')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g315902')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189112')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g642199')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'g189171')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Portugal')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Faro_District_Algarve')){
location <- c(location,'Portugal')
} else if(str_detect(ndf$url[i],'Ile_de_France')){
location <- c(location,'France')
} else{
location <- c(location,NA)
}
}
ndf$location <- location
rm(i, location)
type = c()
for(i in 1:nrow(ndf)){
if(!is.na(ndf$tags[[i]][2])){
if(str_detect(ndf$tags[[i]][2],'Spas et bien-être')){
type <- c(type, 'Spas et bien-être')
} else if(str_detect(ndf$tags[[i]][2],'plein') && str_detect(ndf$tags[[i]][2],'air')){
type <- c(type, 'Activités de plein air')
} else if(str_detect(ndf$tags[[i]][2],'Circuits et activités')){
type <- c(type, 'Circuits et activités')
} else if(str_detect(ndf$tags[[i]][2],'Vie') && str_detect(ndf$tags[[i]][2],'nocturne')){
type <- c(type, 'Vie nocturne')
} else if(str_detect(ndf$tags[[i]][2],'activités')){
type <- c(type, 'Activités')
} else if(str_detect(ndf$tags[[i]][2],'Boire & manger')){
type <- c(type, 'Boire & manger')
} else if(str_detect(ndf$tags[[i]][2],'Shopping')){
type <- c(type, 'Shopping')
} else if(str_detect(ndf$tags[[i]][2],'Transports')){
type <- c(type, 'Transports')
} else if(str_detect(ndf$tags[[i]][2],'Cours et atelier')){
type <- c(type, 'Cours et atelier')
} else if(str_detect(ndf$tags[[i]][2],'Sites touristiques')){
type <- c(type, 'Sites touristiques')
} else {
type <- c(type, 'Autres')
}
} else {
type <- c(type, NA)
}
}
ndf$type <- type
rm(i, type)
rm(df)
#################### Comments
regex_pattern <- "France"
query <- paste0(paste0('{"comment_location": {"$regex": "',regex_pattern),'", "$options": "i"}}')
comments_french <- as.data.frame(comments$find(query = query))
#################### Final DF
df <- merge(comments_french, ndf, by = "url", all.x = TRUE)
df_new_york <- df[df$location == "New-york", ]
df_dubai$comment_rank_val <- str_extract(df_dubai$comment_rank, '\\d,\\d')
df_dubai <- df[df$location == "Dubai", ]
df_dubai <- na.omit(df_dubai)
length(distinct(df_dubai$profile_name))
length(unique(df_dubai$profile_name))
length(unique(df_new_york$profile_name))
plot(cars)
library(httr)
install.packages(c("httr", "rvest", "dplyr"))
library(httr)
library(rvest)
library(dplyr)
# URL of the web page
url <- 'http://books.toscrape.com/catalogue/category/books_1/index.html'
# Fetch the web page
webpage <- GET(url)
# Parse the HTML
content <- content(webpage, as = 'text')
parsed_html <- read_html(content)
# Extract data (example: book titles, prices, and availability)
titles <- parsed_html %>% html_nodes('.product_pod h3 a') %>% html_attr('title')
prices <- parsed_html %>% html_nodes('.product_pod .price_color') %>% html_text()
availabilities <- parsed_html %>% html_nodes('.product_pod .instock.availability') %>% html_text(trim = TRUE)
# Create a DataFrame
df <- data.frame(Title = titles, Price = prices, Availability = availabilities)
# Display the DataFrame
print(head(df))
install.packages(c("foreign", "MASS", "nlme", "survival", "withr"))
install.packages(c('rvest','dplyr'))
install.packages(c("rvest", "dplyr"))
library(rvest)  # For web scraping
library(dplyr)  # For data manipulation
url <- 'http://books.toscrape.com'
page <- read_html(url)
books <- page %>% html_nodes('article.product_pod')
# Initialize lists to hold extracted data
titles <- c()
prices <- c()
availabilities <- c()
ratings <- c()
# Step 3: Loop through each book and extract details
for (book in books){
# Title
title <- book %>%
html_node('h3 a') %>%
html_attr('title')
titles <- c(titles, title)
# Price
price <-  book %>%
html_node('p.price_color') %>%
html_text()
prices <- c(prices, price)
# Availability
availability <-  book %>%
html_node('p.instock.availability') %>%
html_text(trim=TRUE)
# Rating
rating <- book %>%
html_node('p.star-rating') %>%
html_attr('class')
rating <- gsub('star-rating','',rating)
ratings <- c(ratings, rating)
}
# Combine data into a data frame
df <- data.frame(
Title = titles,
Price = prices,
Availability = availabilities,
Rating = ratings
)
for (book in books){
# Title
title <- book %>%
html_node('h3 a') %>%
html_attr('title')
titles <- c(titles, title)
# Price
price <-  book %>%
html_node('p.price_color') %>%
html_text()
prices <- c(prices, price)
# Availability
availability <-  book %>%
html_node('p.instock.availability') %>%
html_text(trim=TRUE)
availabilities <- c(availabilities, availability)
# Rating
rating <- book %>%
html_node('p.star-rating') %>%
html_attr('class')
rating <- gsub('star-rating','',rating)
ratings <- c(ratings, rating)
}
# Combine data into a data frame
df <- data.frame(
Title = titles,
Price = prices,
Availability = availabilities,
Rating = ratings
)
print(df)
View(df)
# Initialize lists to hold extracted data
titles <- c()
prices <- c()
availabilities <- c()
ratings <- c()
# Step 3: Loop through each book and extract details
for (book in books){
# Title
title <- book %>%
html_node('h3 a') %>%
html_attr('title')
titles <- c(titles, title)
# Price
price <-  book %>%
html_node('p.price_color') %>%
html_text()
prices <- c(prices, price)
# Availability
availability <-  book %>%
html_node('p.instock.availability') %>%
html_text(trim=TRUE)
availabilities <- c(availabilities, availability)
# Rating
rating <- book %>%
html_node('p.star-rating') %>%
html_attr('class')
rating <- gsub('star-rating','',rating)
ratings <- c(ratings, rating)
}
# Combine data into a data frame
df <- data.frame(
Title = titles,
Price = prices,
Availability = availabilities,
Rating = ratings
)
# Display the result
print(df)
# Assuming there are 50 pages
for(page_num in 2:50){
# Construct the url for each page
url <- paste0('http://books.toscrape.com/catalogue/page-',page_num,'.html')
page <- read_html(url)
books <- page %>% html_nodes('article.product_pod')
for (book in books){
# Title
title <- book %>%
html_node('h3 a') %>%
html_attr('title')
titles <- c(titles, title)
# Price
price <-  book %>%
html_node('p.price_color') %>%
html_text()
prices <- c(prices, price)
# Availability
availability <-  book %>%
html_node('p.instock.availability') %>%
html_text(trim=TRUE)
availabilities <- c(availabilities, availability)
# Rating
rating <- book %>%
html_node('p.star-rating') %>%
html_attr('class')
rating <- gsub('star-rating','',rating)
ratings <- c(ratings, rating)
}
}
df <- data.frame(
Title = titles,
Price = prices,
Availability = availabilities,
Rating = ratings
)
# Display the combined result
print(df)
View(df)
setwd("~/Documents/GitHub/Hands-on-Machine-Learning/Data Exploration/data")
# Load necessary libraries
library(ggplot2)
library(dplyr)
# Load the dataset
supermarket <- read.csv("detailed_supermarket_sales.csv")
library(gridExtra)
install.packages("gridExtra")
library(gridExtra)
# 1. Boxplot: Total Sales by Product Line
p1 <- ggplot(supermarket, aes(x = `Product.line`, y = Total)) +
geom_boxplot() +
labs(title = 'Boxplot of Total Sales by Product Line') +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# 2. Scatter plot: Unit Price vs Quantity by Product Line
p2 <- ggplot(supermarket, aes(x = Unit.price, y = Quantity, color = `Product.line`)) +
geom_point() +
labs(title = 'Scatter Plot of Unit Price vs Quantity by Product Line')
# 3. Histogram: Distribution of Total Sales
p3 <- ggplot(supermarket, aes(x = Total)) +
geom_histogram(bins = 20, fill = 'skyblue', color = 'black') +
geom_density(aes(y = ..density.. * max(..count..)), color = 'red') +
labs(title = 'Distribution of Total Sales', x = 'Total Sales')
# 4. Bar chart: Product Line Distribution
p4 <- supermarket %>%
count(`Product.line`) %>%
ggplot(aes(x = reorder(`Product.line`, n), y = n)) +
geom_bar(stat = "identity", fill = 'skyblue') +
labs(title = 'Bar Chart of Product Line Distribution', x = 'Product Line', y = 'Count') +
coord_flip()
# 5. Stacked Bar chart: Product Line by Gender
p5 <- supermarket %>%
count(Gender, `Product.line`) %>%
ggplot(aes(x = Gender, y = n, fill = `Product.line`)) +
geom_bar(stat = "identity", position = "stack") +
labs(title = 'Stacked Bar Chart of Product Line by Gender', x = 'Gender', y = 'Count')
# 6. Pie chart: Gender Distribution
p6 <- supermarket %>%
count(Gender) %>%
ggplot(aes(x = "", y = n, fill = Gender)) +
geom_bar(stat = "identity", width = 1) +
coord_polar(theta = "y") +
labs(title = 'Pie Chart of Gender Distribution') +
theme_void() +
geom_text(aes(label = scales::percent(n / sum(n))), position = position_stack(vjust = 0.5)) +
scale_fill_manual(values = c('lightblue', 'lightgreen'))
# Arrange the plots into a 3x2 grid
grid.arrange(p1, p2, p3, p4, p5, p6, ncol = 2)
